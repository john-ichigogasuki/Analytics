{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/john/anaconda3/envs/newenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tabularisai/multilingual-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label ID: 4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 推論関数を定義 (例)\n",
    "def predict_sentiment(text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_id = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_id\n",
    "\n",
    "# テスト推論\n",
    "sample_text = \"I love this product. It's really amazing!\"\n",
    "sentiment = predict_sentiment(sample_text)\n",
    "print(\"Predicted label ID:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Very Negative', 1: 'Negative', 2: 'Neutral', 3: 'Positive', 4: 'Very Positive'}\n"
     ]
    }
   ],
   "source": [
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Hiraoka.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Hiraoka.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Mori.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Mori.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Abe.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Abe.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Suto.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Suto.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Sakai.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Sakai.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Pang.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Pang.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Futamura.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Futamura.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Mori.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Mori.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Futamura.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Futamura.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Sakai.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Sakai.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Shiojiri.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Shiojiri.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Suto.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Suto.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_beta_Hiraoka.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_beta_Hiraoka.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Abe.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Abe.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Shiojiri.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Shiojiri.csv\n",
      "\n",
      "=== 処理中: ./Analyzed/AnalyzedData/analyzed_alpha_Pang.csv ===\n",
      "上書き保存完了: ./Analyzed/AnalyzedData/analyzed_alpha_Pang.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "def analyze_sentiment_in_csvs(input_pattern: str):\n",
    "    \"\"\"\n",
    "    指定したパターンにマッチするCSVファイルをすべて読み込み、\n",
    "    'Detail' 列 (index=1) に対して感情分析を行い、\n",
    "    新たな列 'Sentiment' を追加して、同じファイル名で上書き保存する関数。\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_pattern : str\n",
    "        読み込むファイルパスのパターン。\n",
    "        例: \"root/Analyzed/AnalyzedData/analyzed_*_*.csv\"\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Sentiment Analysis パイプラインの準備\n",
    "    #    多言語の感情分析を想定し、Hugging Faceから公開されているモデルを利用\n",
    "    #    例: \"tabularisai/multilingual-sentiment-analysis\"\n",
    "    sentiment_pipeline = pipeline(\n",
    "        task=\"sentiment-analysis\",\n",
    "        model=\"tabularisai/multilingual-sentiment-analysis\"\n",
    "    )\n",
    "\n",
    "    # 2. 指定パターンに合うCSVをすべて取得\n",
    "    csv_files = glob.glob(input_pattern)\n",
    "    if not csv_files:\n",
    "        print(f\"パターン {input_pattern} に合致するCSVファイルがありません。処理を終了します。\")\n",
    "        return\n",
    "\n",
    "    for csv_path in csv_files:\n",
    "        print(f\"=== 処理中: {csv_path} ===\")\n",
    "\n",
    "        # 3. CSVを読み込む\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # dfのカラム構造:\n",
    "        #   column[0]: Speaker\n",
    "        #   column[1]: Detail\n",
    "        #   column[2]: UniqueWords\n",
    "        #   column[3]: JLPTLevel\n",
    "        # → 新たに column[4] (5列目) に感情分析結果を追加\n",
    "\n",
    "        # 4. Detail列に対して感情分析を適用\n",
    "        sentiments = []\n",
    "        for text in df[\"Detail\"]:\n",
    "            result = sentiment_pipeline(text)\n",
    "            label = result[0][\"label\"]  # 例: \"positive\", \"negative\", \"neutral\"など\n",
    "            sentiments.append(label)\n",
    "\n",
    "        # 5. 新しい列として追加\n",
    "        df[\"Sentiment\"] = sentiments\n",
    "\n",
    "        # 6. 同じファイル名で上書き保存\n",
    "        #    ※ 元データが必要な場合はバックアップを取るなどご注意ください\n",
    "        df.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "        print(f\"上書き保存完了: {csv_path}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 例: \"root/Analyzed/AnalyzedData/analyzed_*_*.csv\" で\n",
    "    # analyzed_alpha_{name}.csv, analyzed_beta_{name}.csv を処理する想定。\n",
    "    pattern = \"./Analyzed/AnalyzedData/analyzed_*_*.csv\"\n",
    "    analyze_sentiment_in_csvs(input_pattern=pattern)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
